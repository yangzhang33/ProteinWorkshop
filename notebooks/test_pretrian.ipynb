{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install graphein from master for bleeding-edge additions\n",
    "# !pip install git+https://github.com/a-r-j/graphein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/19/24 10:55:04] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> No `.env` file found in project root. Checking for env vars<span style=\"color: #808000; text-decoration-color: #808000\">...</span>         <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">constants.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py#22\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/19/24 10:55:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m No `.env` file found in project root. Checking for env vars\u001b[33m...\u001b[0m         \u001b]8;id=802056;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py\u001b\\\u001b[2mconstants.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=220024;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py#22\u001b\\\u001b[2m22\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> No env var `DATA_PATH` found. Setting default<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                       <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">constants.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py#28\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m No env var `DATA_PATH` found. Setting default\u001b[33m...\u001b[0m                       \u001b]8;id=270851;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py\u001b\\\u001b[2mconstants.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=621215;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py#28\u001b\\\u001b[2m28\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> DATA_PATH:                                                             <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">constants.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py#39\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">39</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">data</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m DATA_PATH:                                                             \u001b]8;id=577871;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py\u001b\\\u001b[2mconstants.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=790709;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/constants.py#39\u001b\\\u001b[2m39\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m/home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/\u001b[0m\u001b[95mdata\u001b[0m           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/19/24 10:55:05] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Hydra initialised at                                                    <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/utils/notebook.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">notebook.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/utils/notebook.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">config.</span>         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/19/24 10:55:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Hydra initialised at                                                    \u001b]8;id=713304;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/utils/notebook.py\u001b\\\u001b[2mnotebook.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=196155;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/utils/notebook.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m/home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/\u001b[0m\u001b[95mconfig.\u001b[0m         \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88313/593657413.py:19: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  hydra.initialize(rel_path)\n"
     ]
    }
   ],
   "source": [
    "# Misc. tools\n",
    "import os\n",
    "\n",
    "# Hydra tools\n",
    "import hydra\n",
    "\n",
    "from hydra.compose import GlobalHydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "\n",
    "from proteinworkshop.constants import HYDRA_CONFIG_PATH\n",
    "from proteinworkshop.utils.notebook import init_hydra_singleton\n",
    "\n",
    "init_hydra_singleton(reload=True)\n",
    "\n",
    "path = HYDRA_CONFIG_PATH\n",
    "rel_path = os.path.relpath(path, start=\".\")\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "hydra.initialize(rel_path)\n",
    "\n",
    "cfg = hydra.compose(\n",
    "    \"train\",\n",
    "    overrides=[\n",
    "        \"dataset=afdb_swissprot_v4\",\n",
    "        \"dataset.datamodule.batch_size=32\",\n",
    "        \"dataset.datamodule.train_split=0.02\", # here\n",
    "        \"dataset.datamodule.val_split=0.001\", # here\n",
    "        \"features=fe_subgraph\",\n",
    "\n",
    "        \"task=subgraph_distance_prediction\", # here\n",
    "        ],\n",
    "    return_hydra_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/19/24 10:55:06] </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> CUDA available: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                                                     <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#249\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/19/24 10:55:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m CUDA available: \u001b[3;92mTrue\u001b[0m                                                     \u001b]8;id=922542;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=162453;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#249\u001b\\\u001b[2m249\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Requested GPUs: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.                                                       <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#250\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">250</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Requested GPUs: \u001b[1;36m1\u001b[0m.                                                       \u001b]8;id=928796;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=18634;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#250\u001b\\\u001b[2m250\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> GPU count set to: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                      <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#255\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">255</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m GPU count set to: \u001b[1;36m1\u001b[0m                                                      \u001b]8;id=830072;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=4616;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#255\u001b\\\u001b[2m255\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> You are not using early stopping.                                        <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#165\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m You are not using early stopping.                                        \u001b]8;id=933580;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=816137;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#165\u001b\\\u001b[2m165\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from proteinworkshop.configs import config\n",
    "\n",
    "cfg = config.validate_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['env', 'dataset', 'features', 'encoder', 'decoder', 'transforms', 'callbacks', 'optimiser', 'scheduler', 'trainer', 'extras', 'metrics', 'task', 'logger', 'name', 'seed', 'num_workers', 'task_name', 'test'])\n",
      "env\n",
      "{'paths': {'root_dir': '${oc.env:ROOT_DIR}', 'data': '${oc.env:DATA_PATH}', 'output_dir': '${hydra:runtime.output_dir}', 'work_dir': '${hydra:runtime.cwd}', 'log_dir': '${oc.env:RUNS_PATH}', 'runs': '${oc.env:RUNS_PATH}', 'run_dir': '${env.paths.runs}/${name}/${env.init_time}'}, 'python': {'version': '${python_version:micro}'}, 'init_time': '${now:%y-%m-%d_%H:%M:%S}'}\n",
      "dataset\n",
      "{'datamodule': {'_target_': 'graphein.ml.datasets.foldcomp_dataset.FoldCompLightningDataModule', 'data_dir': '${env.paths.data}/afdb_swissprot_v4/', 'database': 'afdb_swissprot_v4', 'batch_size': 32, 'num_workers': 32, 'train_split': 0.02, 'val_split': 0.001, 'test_split': 0.1, 'pin_memory': True, 'use_graphein': True, 'transform': '${transforms}'}, 'dataset_name': 'afdb_swissprot_v4', 'num_classes': 'None'}\n",
      "features\n",
      "{'_target_': 'proteinworkshop.features.factory.ProteinFeaturiser', 'representation': 'CA', 'scalar_node_features': ['amino_acid_one_hot'], 'vector_node_features': [], 'edge_types': [], 'scalar_edge_features': [], 'vector_edge_features': [], 'subgraph_pretraining_edges': [10.0, 32], 'compute_subgraphs': [2, 0.1]}\n",
      "encoder\n",
      "{'_target_': 'proteinworkshop.models.graph_encoders.egnn.EGNNModel', 'num_layers': 6, 'emb_dim': 512, 'activation': 'relu', 'norm': 'batch', 'aggr': 'sum', 'pool': 'mean', 'residual': True, 'dropout': 0.1}\n",
      "decoder\n",
      "{'subgraph_distances': {'_target_': 'proteinworkshop.models.decoders.mlp_dist.MLP_Pred_Dist', 'hidden_channels': 128, 'input': 'fused_repr'}}\n",
      "transforms\n",
      "{'remove_missing_ca': {'_target_': 'proteinworkshop.tasks.remove_missing_ca.RemoveMissingCa', 'fill_value': 1e-05, 'ca_idx': 1}}\n",
      "callbacks\n",
      "{'model_checkpoint': {'_target_': 'lightning.pytorch.callbacks.ModelCheckpoint', 'dirpath': '${env.paths.output_dir}/checkpoints', 'filename': 'epoch_{epoch:03d}', 'monitor': 'val/subgraph_distances/mse', 'verbose': True, 'save_last': True, 'save_top_k': 1, 'mode': 'min', 'auto_insert_metric_name': False, 'save_weights_only': False, 'every_n_train_steps': None, 'train_time_interval': None, 'every_n_epochs': None, 'save_on_train_epoch_end': None}, 'early_stopping': {'_target_': 'lightning.pytorch.callbacks.EarlyStopping', 'monitor': 'val/subgraph_distances/mse', 'min_delta': 0.0, 'patience': 10, 'verbose': True, 'mode': 'min', 'strict': True, 'check_finite': True, 'stopping_threshold': None, 'divergence_threshold': None, 'check_on_train_epoch_end': False}, 'model_summary': {'_target_': 'lightning.pytorch.callbacks.RichModelSummary', 'max_depth': -1}, 'rich_progress_bar': {'_target_': 'lightning.pytorch.callbacks.RichProgressBar'}, 'learning_rate_monitor': {'_target_': 'lightning.pytorch.callbacks.LearningRateMonitor'}, 'stop_on_nan': {'_target_': 'lightning.pytorch.callbacks.EarlyStopping', 'monitor': 'train/loss/total', 'min_delta': 0.0, 'patience': 10000000, 'verbose': True, 'mode': 'min', 'strict': True, 'check_finite': True, 'stopping_threshold': None, 'divergence_threshold': None, 'check_on_train_epoch_end': None}}\n",
      "optimiser\n",
      "{'optimizer': {'_target_': 'torch.optim.Adam', '_partial_': True, 'lr': 0.001, 'weight_decay': 0.0}}\n",
      "scheduler\n",
      "{}\n",
      "trainer\n",
      "{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${env.paths.output_dir}', 'min_epochs': 1, 'max_epochs': 10, 'accelerator': 'gpu', 'check_val_every_n_epoch': 1, 'deterministic': False, 'num_sanity_val_steps': 2, 'devices': 1}\n",
      "extras\n",
      "{'ignore_warnings': True, 'enforce_tags': False, 'print_config': True}\n",
      "metrics\n",
      "{'mse': {'_target_': 'torchmetrics.MeanSquaredError'}}\n",
      "task\n",
      "{'task': 'subgraph_distance_prediction', 'losses': {'subgraph_distances': 'mse_loss'}, 'label_smoothing': 0.0, 'output': ['subgraph_distances'], 'supervise_on': ['subgraph_distances']}\n",
      "logger\n",
      "{'csv': {'_target_': 'lightning.pytorch.loggers.csv_logs.CSVLogger', 'save_dir': '${env.paths.output_dir}', 'name': 'csv/', 'prefix': ''}}\n",
      "name\n",
      "\n",
      "seed\n",
      "52\n",
      "num_workers\n",
      "16\n",
      "task_name\n",
      "train\n",
      "test\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(cfg.keys())\n",
    "for key in cfg.keys():\n",
    "    print(key)\n",
    "    print(cfg[key])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a dataset\n",
    "\n",
    "Can switch out for another by replacing the dataset arg in overrides:\n",
    "\n",
    "`cfg = hydra.compose(\"template\", overrides=[\"dataset=afdb_swissprot_v4\"], return_hydra_config=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> CUDA available: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                                                     <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#249\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m CUDA available: \u001b[3;92mTrue\u001b[0m                                                     \u001b]8;id=406051;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=365417;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#249\u001b\\\u001b[2m249\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Requested GPUs: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.                                                       <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#250\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">250</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m Requested GPUs: \u001b[1;36m1\u001b[0m.                                                       \u001b]8;id=710739;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=843278;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#250\u001b\\\u001b[2m250\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> GPU count set to: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                      <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#255\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">255</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mDEBUG   \u001b[0m GPU count set to: \u001b[1;36m1\u001b[0m                                                      \u001b]8;id=488699;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=333809;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#255\u001b\\\u001b[2m255\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> You are not using early stopping.                                        <a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#165\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m You are not using early stopping.                                        \u001b]8;id=461409;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py\u001b\\\u001b[2mconfig.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=178560;file:///home/zhang/Projects/3d/ProteinWorkshop/proteinworkshop/configs/config.py#165\u001b\\\u001b[2m165\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 542378/542378 [00:00<00:00, 4672582.55it/s]\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 542378/542378 [00:00<00:00, 4710958.31it/s]\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 542378/542378 [00:00<00:00, 4749642.38it/s]\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 542378/542378 [00:00<00:00, 4747144.73it/s]\n",
      "Processing...\n",
      "Done!\n",
      "/home/zhang/miniconda3/envs/3d/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning:\n",
      "\n",
      "This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 28, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProteinBatch(fill_value=[32], atom_list=[32], coords=[11716, 37, 3], residues=[32], residue_id=[32], chains=[11716], residue_type=[11716], b_factor=[11716], id=[32], x=[11716], seq_pos=[11716, 1], batch=[11716], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "from proteinworkshop.configs import config\n",
    "\n",
    "cfg = config.validate_config(cfg)\n",
    "# print(\"Original config:\\n\", OmegaConf.to_yaml(cfg))\n",
    "mutable_cfg = OmegaConf.to_container(cfg.dataset.datamodule, resolve=True)\n",
    "mutable_cfg = OmegaConf.create(mutable_cfg)\n",
    "# print(\"Cloned config:\\n\", OmegaConf.to_yaml(mutable_cfg))\n",
    "# Instantiate the datamodule with the mutable configuration\n",
    "datamodule = hydra.utils.instantiate(mutable_cfg)\n",
    "datamodule.setup(\"fit\")\n",
    "dl = datamodule.train_dataloader()\n",
    "dl = datamodule.val_dataloader()\n",
    "for i in dl:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProteinBatch(fill_value=[32], atom_list=[32], coords=[11716, 37, 3], residues=[32], residue_id=[32], chains=[11716], residue_type=[11716], b_factor=[11716], id=[32], x=[11716, 23], seq_pos=[11716, 1], batch=[11716], ptr=[33], pos=[11716, 3], edge_index=[2, 185106], subgraphs=[1157, 148], subgraph_distances=[1157], subgraph_lengths=[1157])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "featuriser: nn.Module = hydra.utils.instantiate(cfg.features)\n",
    "\n",
    "for i in dl:\n",
    "    batch = featuriser(i)\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a new encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from torch_scatter import scatter_mean, scatter\n",
    "import torch\n",
    "def train(args, model, mlp_pred_dist, train_loader,  criterion, optimizer, device):\n",
    "    model.train()\n",
    "    mlp_pred_dist.train()\n",
    "    loss_accum = 0\n",
    "   \n",
    "    # shuffle the train batches and all_subgraphs\n",
    "    #random_idx = np.random.permutation(len(train_batches))\n",
    "    #train_batches = [train_batches[i] for i in random_idx]\n",
    "    \n",
    "    \n",
    "    #for step, batch in enumerate(tqdm(loader, disable=args.disable_tqdm)):\n",
    "    for step, batch in enumerate(tqdm(train_loader, disable=args.disable_tqdm)):\n",
    "        batch = featuriser(batch)\n",
    "        #init_idx = random_idx[step]\n",
    "        init_idx = step\n",
    "        if args.mask:\n",
    "            # random mask node aatype\n",
    "            mask_indice = torch.tensor(np.random.choice(batch.num_nodes, int(batch.num_nodes * args.mask_aatype), replace=False))\n",
    "            batch.x[:, 0][mask_indice] = 25\n",
    "        if args.noise:\n",
    "            # add gaussian noise to atom coords\n",
    "            gaussian_noise = torch.clip(torch.normal(mean=0.0, std=0.1, size=batch.coords_ca.shape), min=-0.3, max=0.3)\n",
    "            batch.coords_ca += gaussian_noise\n",
    "            if args.level != 'aminoacid':\n",
    "                batch.coords_n += gaussian_noise\n",
    "                batch.coords_c += gaussian_noise\n",
    "        if args.deform:\n",
    "            # Anisotropic scale\n",
    "            deform = torch.clip(torch.normal(mean=1.0, std=0.1, size=(1, 3)), min=0.9, max=1.1)\n",
    "            batch.coords_ca *= deform\n",
    "            if args.level != 'aminoacid':\n",
    "                batch.coords_n *= deform\n",
    "                batch.coords_c *= deform\n",
    "        batch = batch.to(device)\n",
    "                      \n",
    "        pred = model(batch) \n",
    "        \n",
    "        subgraphs = batch.subgraphs\n",
    "        dist = batch.subgraph_distances.to(device)\n",
    "\n",
    "        #aggregate node representations of each subgraph\n",
    "\n",
    "        pooled_subgraphs = []\n",
    "        for i in range(len(subgraphs)):\n",
    "            pooled_subgraphs.append(torch.sum(pred[subgraphs[i]], dim=0))\n",
    "\n",
    "        pooled_subgraphs = torch.stack(pooled_subgraphs)\n",
    "        graph_repr = scatter(pred, batch.batch, dim=0)\n",
    "        # for lin in model.lins_out:\n",
    "        #     pooled_subgraphs = model.relu(lin(pooled_subgraphs))\n",
    "        #     pooled_subgraphs = model.dropout(pooled_subgraphs)     \n",
    "        \n",
    "        #protein representations\n",
    "        #compute the center of the subgraphs based on the coordinates\n",
    "       \n",
    "        #compute the center of the protein based on the coordinates\n",
    "        # compute the distance between the center of the subgraphs and the center of the proteins\n",
    "        # we have to compute the distance only between the subgraph and the corresponding protein\n",
    "        # repeat the center of the protein for each subgraph and the perform the distance computation\n",
    "        #G_c = G_c.repeat(num_subgraphs_per_protein,1)\n",
    "\n",
    "        \n",
    "        #dist = torch.norm(G_c-S_c,dim=1)\n",
    "        #concat the subgraph and the protein representations. find the graph_repr that corresponds to the subgraph of the protein\n",
    "        fused_repr = []\n",
    "        for i in range(len(pooled_subgraphs)):\n",
    "            fused_repr.append(torch.cat((pooled_subgraphs[i],graph_repr[batch.batch[subgraphs[i][0]]])))\n",
    "        fused_repr = torch.stack(fused_repr)\n",
    "        #predict the distance\n",
    "        pred_dist = mlp_pred_dist(fused_repr)\n",
    "        pred_dist = pred_dist.squeeze()\n",
    "        #normalize the distance (note maybe we should normalize in the whole dataset and not in each bach)\n",
    "        y_dist = dist/torch.max(dist)\n",
    "        #mse loss\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(pred_dist, y_dist)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_accum += loss.item()\n",
    "        if(step%300==0):\n",
    "            print(loss_accum/(step + 1))\n",
    "        #### end pretraining\n",
    "        ######\n",
    "    print('train loss epoch: ', loss_accum/(step + 1) )\n",
    "    return loss_accum/(step + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(args, model, mlp_pred_dist, loader, criterion, device):    \n",
    "    model.eval()\n",
    "    \n",
    "    loss_accum = 0\n",
    "    for step, batch in enumerate(tqdm(loader, disable=args.disable_tqdm)):\n",
    "        batch = featuriser(batch)\n",
    "        if args.mask:\n",
    "            # random mask node aatype\n",
    "            mask_indice = torch.tensor(np.random.choice(batch.num_nodes, int(batch.num_nodes * args.mask_aatype), replace=False))\n",
    "            batch.x[:, 0][mask_indice] = 25\n",
    "        if args.noise:\n",
    "            # add gaussian noise to atom coords\n",
    "            gaussian_noise = torch.clip(torch.normal(mean=0.0, std=0.1, size=batch.coords_ca.shape), min=-0.3, max=0.3)\n",
    "            batch.coords_ca += gaussian_noise\n",
    "            if args.level != 'aminoacid':\n",
    "                batch.coords_n += gaussian_noise\n",
    "                batch.coords_c += gaussian_noise\n",
    "        if args.deform:\n",
    "            # Anisotropic scale\n",
    "            deform = torch.clip(torch.normal(mean=1.0, std=0.1, size=(1, 3)), min=0.9, max=1.1)\n",
    "            batch.coords_ca *= deform\n",
    "            if args.level != 'aminoacid':\n",
    "                batch.coords_n *= deform\n",
    "                batch.coords_c *= deform\n",
    "        batch = batch.to(device)\n",
    "                     \n",
    "        \n",
    "        pred = model(batch) \n",
    "        \n",
    "        \n",
    "\n",
    "        subgraphs = batch.subgraphs\n",
    "        dist = batch.subgraph_distances.to(device)\n",
    "        #### pretraining\n",
    "        #aggregate node representations of each subgraph\n",
    "\n",
    "\n",
    "        pooled_subgraphs = []\n",
    "        for i in range(len(subgraphs)):\n",
    "            pooled_subgraphs.append(torch.sum(pred[subgraphs[i]], dim=0))\n",
    "      \n",
    "        pooled_subgraphs = torch.stack(pooled_subgraphs)\n",
    "\n",
    "        # for lin in model.lins_out:\n",
    "        #     pooled_subgraphs = model.relu(lin(pooled_subgraphs))\n",
    "        #     pooled_subgraphs = model.dropout(pooled_subgraphs)    \n",
    "        #protein representations\n",
    "        #compute the center of the subgraphs based on the coordinates\n",
    "\n",
    "        #compute the center of the protein based on the coordinates\n",
    "        # compute the distance between the center of the subgraphs and the center of the proteins\n",
    "        # we have to compute the distance only between the subgraph and the corresponding protein\n",
    "        # repeat the center of the protein for each subgraph and the perform the distance computation\n",
    "        #G_c = G_c.repeat(num_subgraphs_per_protein,1)\n",
    "\n",
    "        \n",
    "        #dist = torch.norm(G_c-S_c,dim=1)\n",
    "        #normalize the distance (note maybe we should normalize in the whole dataset and not in each bach)\n",
    "        graph_repr = scatter(pred, batch.batch, dim=0)\n",
    "        fused_repr = []\n",
    "        for i in range(len(pooled_subgraphs)):\n",
    "            fused_repr.append(torch.cat((pooled_subgraphs[i],graph_repr[batch.batch[subgraphs[i][0]]])))\n",
    "        fused_repr = torch.stack(fused_repr)\n",
    "        y_dist = dist/torch.max(dist)\n",
    "        #predict the distance\n",
    "        pred_dist = mlp_pred_dist(fused_repr)\n",
    "        pred_dist = pred_dist.squeeze()\n",
    "        #mse loss\n",
    "        loss = criterion(pred_dist, y_dist)\n",
    "        loss_accum += loss.item()\n",
    "        if(step %100 == 0):\n",
    "            print(loss_accum/(step + 1))\n",
    "    print('eval loss epoch: ', loss_accum/(step + 1))\n",
    "    return loss_accum/(step + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Train & Val & Test Data...\n",
      "num_parameters: 1433344\n",
      "339\n",
      "Loaded subgraphs\n",
      "==== Epoch 1 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:04<24:04,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19333094358444214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:05<01:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06004828708462937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:20<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.05867409093475799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<11:51,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02635742351412773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:52<01:57,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03942182510722392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:46<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.03992581272667105\n",
      "Train: Loss:0.058674, time:906.9469184440095, train_time:620.4321674219973\n",
      "==== Epoch 2 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:03<22:29,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024970002472400665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:15<01:14,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046417944832547166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:23<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.04555778847155669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<12:07,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10035014897584915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:52<01:57,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06426998904657245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:46<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.06200156705171773\n",
      "Train: Loss:0.045558, time:909.3110188319988, train_time:623.0785406450013\n",
      "==== Epoch 3 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:03<22:18,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054526835680007935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:16<01:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03933691680493248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:22<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.040142245005519515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<11:59,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05959140881896019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:53<01:58,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04970447140017358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:46<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.049263358308058794\n",
      "Train: Loss:0.040142, time:909.3881620059983, train_time:622.5458605159947\n",
      "==== Epoch 4 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:05<29:04,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05154261738061905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:17<01:05,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03805944661105491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:23<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.03805751212018166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<11:55,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024155309423804283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:53<01:57,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03334032532085877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:46<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.034935878200287165\n",
      "Train: Loss:0.038058, time:909.8540852959995, train_time:623.2159066159948\n",
      "==== Epoch 5 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:04<25:17,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021312864497303963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:11<01:10,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03035295474346096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:22<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.030151901722701602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<12:23,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016864396631717682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:53<01:58,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02622215389873427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:46<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.027736526767187047\n",
      "Train: Loss:0.030152, time:909.4134876539902, train_time:622.6849301890034\n",
      "==== Epoch 6 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:04<26:36,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017745036631822586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:12<01:23,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03124060809141972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:23<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.03150184058576031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<11:57,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017394671216607094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:52<01:58,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028397551839156907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:46<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.028883139546396153\n",
      "Train: Loss:0.031502, time:910.1711360140034, train_time:623.6630888109939\n",
      "==== Epoch 7 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:05<29:59,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03609895706176758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:18<01:12,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0278279707299861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:25<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.027316197406797284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<12:07,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02230650745332241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:52<01:57,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025128639616662323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:46<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.02581789732318033\n",
      "Train: Loss:0.027316, time:912.3694836729992, train_time:625.8477841529966\n",
      "==== Epoch 8 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:04<23:17,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013320054858922958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:18<01:08,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026852127009897534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:26<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.026765850026457184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<12:31,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016851380467414856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:53<01:58,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024040494805736706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:47<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.024804918806661257\n",
      "Train: Loss:0.026766, time:914.111687134995, train_time:626.8559465879953\n",
      "==== Epoch 9 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:04<27:50,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019249556586146355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:12<01:05,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027206222276107417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:23<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.027334844322660857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<12:08,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013516737148165703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:53<01:57,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0243061199267902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:46<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.025090810543659962\n",
      "Train: Loss:0.027335, time:910.4465467270056, train_time:623.5201317340106\n",
      "==== Epoch 10 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/339 [00:04<23:18,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01678326353430748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 301/339 [09:12<01:20,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025918189182481496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [10:21<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss epoch:  0.02560640700919702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/165 [00:04<12:13,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013540513813495636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 101/165 [02:52<01:57,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02471251428901854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [04:45<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss epoch:  0.026172691792475455\n",
      "Train: Loss:0.025606, time:907.723735299005, train_time:621.7440614070074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "#     ### Args\n",
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "from pronet import ProNet\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "sys.argv = ['notebook']\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--device', type=int, default=0, help='Device to use')\n",
    "parser.add_argument('--num_workers', type=int, default=8, help='Number of workers in Dataloader')\n",
    "\n",
    "### Data\n",
    "# parser.add_argument('--dataset', type=str, default='alphafold', help='Func or fold or all')\n",
    "# parser.add_argument('--dataset_path', type=str, default='/datalake/datastore2/alphafold_v4_pronet_processed', help='path to load and process the data')\n",
    "# parser.add_argument('--annot_fn', type=str, default=\"/home/michail/datadisk/PretrainDas/data/GO_EC_labels_deepfri/nrPDB-GO_2019.06.18_annot.tsv\")\n",
    "# parser.add_argument('--ontology', type=str, default=\"ec\")\n",
    "\n",
    "# data augmentation tricks, see appendix E in the paper (https://openreview.net/pdf?id=9X-hgLDLYkQ)\n",
    "parser.add_argument('--mask', action='store_true', help='Random mask some node type')\n",
    "parser.add_argument('--noise', default=False, action='store_true', help='Add Gaussian noise to node coords')\n",
    "parser.add_argument('--deform', default=False, action='store_true', help='Deform node coords')\n",
    "parser.add_argument('--data_augment_eachlayer', default=True, action='store_true', help='Add Gaussian noise to features')\n",
    "parser.add_argument('--euler_noise', default=False, action='store_true', help='Add Gaussian noise Euler angles')\n",
    "parser.add_argument('--mask_aatype', type=float, default=0.1, help='Random mask aatype to 25(unknown:X) ratio')\n",
    "\n",
    "### Model\n",
    "parser.add_argument('--model_name', type=str, default='pronet', help='rgcn,pronet')\n",
    "#for pronet\n",
    "parser.add_argument('--level', type=str, default='aminoacid', help='Choose from \\'aminoacid\\', \\'backbone\\', and \\'allatom\\' levels')\n",
    "parser.add_argument('--num_blocks', type=int, default=4, help='Model layers')\n",
    "parser.add_argument('--hidden_channels', type=int, default=128, help='Hidden dimension')\n",
    "parser.add_argument('--out_channels', type=int, default=384, help='Number of classes, 1195 for the fold data, 384 for the ECdata')\n",
    "parser.add_argument('--fix_dist', action='store_true')  \n",
    "parser.add_argument('--cutoff', type=float, default=10, help='Distance constraint for building the protein graph') \n",
    "parser.add_argument('--dropout', type=float, default=0.3, help='Dropout')\n",
    "parser.add_argument('--precompute_subgraphs', type=int, default=0, help='Compute the subgraphs')\n",
    "\n",
    "## Training hyperparameter\n",
    "parser.add_argument('--epochs', type=int, default=10, help='Number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--lr_decay_step_size', type=int, default=150, help='Learning rate step size')\n",
    "parser.add_argument('--lr_decay_factor', type=float, default=0.5, help='Learning rate factor') \n",
    "parser.add_argument('--weight_decay', type=float, default=0, help='Weight Decay')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='Batch size during training')\n",
    "parser.add_argument('--eval_batch_size', type=int, default=64, help='Batch size')\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--continue_training', action='store_true')\n",
    "parser.add_argument('--save_dir', type=str, default=\"./logs\", help='Trained model path')\n",
    "\n",
    "parser.add_argument('--disable_tqdm', default=False, action='store_true')\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# if(args.device == 1):\n",
    "#     torch.cuda.set_device(1)\n",
    "\n",
    "##### load datasets\n",
    "print('Loading Train & Val & Test Data...')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "#check if file exists\n",
    "\n",
    "\n",
    "##### set up model\n",
    "if(args.model_name == \"pronet\"):\n",
    "    model = ProNet(num_blocks=args.num_blocks, hidden_channels=args.hidden_channels, out_channels=args.out_channels,\n",
    "            cutoff=args.cutoff, dropout=args.dropout,\n",
    "            data_augment_eachlayer=args.data_augment_eachlayer,\n",
    "            euler_noise = args.euler_noise, level=args.level, pretraining=True)\n",
    "else:\n",
    "    model = RGCN(input_dim=input_dim, hidden_dim=args.hidden_channels, n_layers=6, emb_dim=args.out_channels, dropout=args.dropout, pretraining=True)\n",
    "    \n",
    "model.to(device)\n",
    "\n",
    "mlp_pred_dist = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2*args.hidden_channels, args.hidden_channels),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(args.hidden_channels, 1)\n",
    ").to(device)\n",
    "\n",
    "#linear_pred_dist= torch.nn.Linear(2*args.hidden_channels, 1).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(list(model.parameters())+list(mlp_pred_dist.parameters()), lr=args.lr, weight_decay=args.weight_decay) \n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_decay_step_size, gamma=args.lr_decay_factor)\n",
    "\n",
    "\n",
    "if args.continue_training:\n",
    "    save_dir = args.save_dir\n",
    "    checkpoint = torch.load(save_dir + '/best_val.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    #scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    # save_dir = './pretrained_models_{dataset}/{level}/layer{num_blocks}_cutoff{cutoff}_hidden{hidden_channels}_batch{batch_size}_lr{lr}_{lr_decay_factor}_{lr_decay_step_size}_dropout{dropout}__{time}'.format(\n",
    "    #     dataset=args.dataset, level=args.level, \n",
    "    #     num_blocks=args.num_blocks, cutoff=args.cutoff, hidden_channels=args.hidden_channels, batch_size=args.batch_size, \n",
    "    #     lr=args.lr, lr_decay_factor=args.lr_decay_factor, lr_decay_step_size=args.lr_decay_step_size, dropout=args.dropout, time=datetime.now())\n",
    "    # print('saving to...', save_dir)\n",
    "    start_epoch = 1\n",
    "    \n",
    "num_params = sum(p.numel() for p in model.parameters()) \n",
    "print('num_parameters:', num_params)\n",
    "\n",
    "\n",
    "# writer = SummaryWriter(log_dir=save_dir)\n",
    "#  best_val_loss = 1000\n",
    "# test_at_best_val_loss = 1000\n",
    "\n",
    "    \n",
    "# print(\"loading edge_index\")\n",
    "# with open(\"edge_index_pronet_64.pkl\",\"rb\") as f:\n",
    "#     edge_index = pickle.load(f)\n",
    "# print(\"edge_index loaded\")\n",
    "\n",
    "\n",
    "    \n",
    "print(len(train_loader))\n",
    "# exit()\n",
    "\n",
    "# print(\"Loading subgraphs\")\n",
    "# if(args.precompute_subgraphs==1):\n",
    "#     print(\"Preprocessing - Compute Subgraphs\")\n",
    "#     train_subgraphs,train_dist = compute_subgraphs(train_loader, args=args, device=device)\n",
    "#     with open(f'./subgraphs/alphafold_train_subgraphs_{args.batch_size}_490k.pkl', 'wb') as f:\n",
    "#         pickle.dump(train_subgraphs, f)\n",
    "#     with open(f'./subgraphs/alphafold_train_dist_{args.batch_size}_490k.pkl', 'wb') as f:\n",
    "#         pickle.dump(train_dist, f)\n",
    "# else:\n",
    "#     with open(f'./subgraphs/alphafold_train_subgraphs_{args.batch_size}_490k.pkl', 'rb') as f:\n",
    "#         train_subgraphs = pickle.load(f)\n",
    "#     with open(f'./subgraphs/alphafold_train_dist_{args.batch_size}_490k.pkl', 'rb') as f:\n",
    "#         train_dist = pickle.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "print(\"Loaded subgraphs\")\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, args.epochs+1):\n",
    "    print('==== Epoch {} ===='.format(epoch))\n",
    "    t_start = time.perf_counter()\n",
    "    \n",
    "    train_loss = train(args, model, mlp_pred_dist, train_loader, criterion, optimizer, device)\n",
    "    t_end_train = time.perf_counter()\n",
    "    val_loss = evaluation(args, model, mlp_pred_dist, val_loader, criterion, device)\n",
    "    # t_start_test = time.perf_counter()\n",
    "    # test_loss = evaluation(args, model, linear_pred_dist, test_loader, criterion, device)\n",
    "    \n",
    "    \n",
    "    # t_end_test = time.perf_counter() \n",
    "\n",
    "    # if not save_dir == \"\" and not os.path.exists(save_dir):\n",
    "    #     os.makedirs(save_dir)\n",
    "\n",
    "    t_end = time.perf_counter()\n",
    "    print('Train: Loss:{:.6f}, time:{}, train_time:{}'.format(\n",
    "        train_loss, t_end-t_start, t_end_train-t_start))\n",
    "    \n",
    "    # writer.add_scalar('train_loss', train_loss, epoch)\n",
    "\n",
    "    # scheduler.step()   \n",
    "\n",
    "    # writer.close()    \n",
    "    # print(\"Train Loss\", train_loss)\n",
    "    # Save last model\n",
    "    checkpoint = {'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()} #'scheduler_state_dict': scheduler.state_dict()}\n",
    "    # torch.save(checkpoint, save_dir + \"/epoch{}.pt\".format(epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
